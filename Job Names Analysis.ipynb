{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function cluster_names will grab the JOB Ids from expanded clusterID.csv file, and merge with job names text file and clean merged database in order to generate an html file and pickle file for a specific cluster. The pickle file holds the pandas dataframe of the cluster without the Project IDs. Thus the html file is the final product which holds the dataframe with user id, job id, project id, and job name.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this is the code to grab the job ids and job names from the clusters\n",
    "def cluster_names(cluster_num):\n",
    "    #grabbing the cluster dataframe, this is my specified path but it could be different\n",
    "    #basically you need the cluster directory folder and the clusterID.csv.gz file (compressed)\n",
    "    df = pd.read_csv('/Users/cheriehuang/Downloads/Clean_NFS_kmeans/clusterID.csv')\n",
    "    #grabbing the rows from the cluster you specify with cluster_num\n",
    "    ndf = df[df['Clusters'] == cluster_num]\n",
    "    #grabbing the text file with all the jobnames \n",
    "    job_names = pd.read_fwf('jobs.txt',names = ['JobID', 'JobNames'])\n",
    "    stri = 'cluster%d' % cluster_num\n",
    "    temp_df = ndf.merge(job_names, on = 'JobID', how = 'inner')\n",
    "    temp_df.to_pickle(stri + '.pkl') #making a pickle file of the dataframe just in case\n",
    "    #temp_df['JobNames'].value_counts()  -> gives you the frequency of unique names!\n",
    "    #now grab clean merged\n",
    "    mdf = pd.read_pickle('clean_merged.pkl')\n",
    "    #drop the unnecessary columns and make JobID an int\n",
    "    mdf = mdf[['JobID', 'Project']]\n",
    "    mdf['JobID'] = mdf['JobID'].astype(int)\n",
    "    #now merge the two dataframes together\n",
    "    merged = mdf.merge(temp_df, on = 'JobID', how = 'inner')\n",
    "    #save this into an html file!\n",
    "    merged.to_html(stri + '.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below this markdown is used to open each html file that is given to it, and will generate a pandas dataframe holding the top 5 project ids that occur the most often in that html file. It also will describe the percentage this is of total jobs in that html file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = pd.read_html('DBScanCluster7.html')\n",
    "#for pandas html files are read in as a list of pandas dataframes so grab the first one\n",
    "names = names[0]\n",
    "#counts the frequency of each project ID and puts it in largest to smallest\n",
    "ldf = names['Project'].value_counts().to_frame(name = 'Count')\n",
    "#now grab the total number of rows\n",
    "rows_num = names.shape[0]\n",
    "#now calculate the percentages for each project ID and put it in the dataframe\n",
    "ldf['Percentage'] = (ldf['Count']/rows_num) * 100\n",
    "ldf_h = ldf.head() #grabs the top 5!\n",
    "ldf_h.to_pickle('DBScanCluster7Top.pkl') #converts it to a pickle\n",
    "print ldf_h #or you can just print it for a format that is easy to copy and paste directly\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
